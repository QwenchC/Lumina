"""
Lumina æ˜è§é‡åŒ– - LLM å†³ç­–å¼•æ“
ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œé€‰è‚¡å’ŒæŒä»“ç­–ç•¥å†³ç­–
"""
import json
import asyncio
from datetime import datetime
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
from loguru import logger
import httpx

from app.core.config import settings


@dataclass
class TradingDecision:
    """äº¤æ˜“å†³ç­–"""
    symbol: str
    name: str
    action: str  # buy / sell / hold
    quantity: int
    reason: str
    confidence: float  # 0-1
    target_price: Optional[float] = None
    stop_loss: Optional[float] = None


@dataclass
class AnalysisResult:
    """åˆ†æç»“æœ"""
    market_sentiment: str  # bullish / bearish / neutral
    market_summary: str
    decisions: List[TradingDecision]
    risk_assessment: str
    model_used: str
    tokens_used: int
    latency_ms: int


class LLMClient:
    """LLM å®¢æˆ·ç«¯åŸºç±»"""
    
    def __init__(self, model: str):
        self.model = model
    
    async def chat(self, messages: List[Dict], **kwargs) -> Dict:
        raise NotImplementedError


class GitHubModelsClient(LLMClient):
    """GitHub Models å®¢æˆ·ç«¯ (æ¨è - å…è´¹)"""
    
    def __init__(self, model: str = "openai/gpt-4.1-mini"):
        super().__init__(model)
        self.endpoint = settings.github_models_endpoint
    
    async def chat(self, messages: List[Dict], **kwargs) -> Dict:
        token = settings.get_llm_api_key()
        if not token:
            raise ValueError("GitHub Token æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ GITHUB_TOKEN")
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 4096),
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{self.endpoint}/chat/completions",
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            return response.json()


class OpenAIClient(LLMClient):
    """OpenAI / DeepSeek å…¼å®¹å®¢æˆ·ç«¯"""
    
    def __init__(self, model: str = "gpt-4o", base_url: str = None):
        super().__init__(model)
        self.base_url = base_url or settings.openai_base_url
    
    async def chat(self, messages: List[Dict], **kwargs) -> Dict:
        api_key = settings.get_llm_api_key()
        if not api_key:
            provider = settings.llm_provider.upper()
            raise ValueError(f"{provider} API Key æœªé…ç½®ï¼Œè¯·è®¾ç½®å¯¹åº”çš„ç¯å¢ƒå˜é‡")
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 4096),
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            return response.json()


class LLMDecisionEngine:
    """LLM å†³ç­–å¼•æ“"""
    
    # ç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡åŒ–äº¤æ˜“åˆ†æå¸ˆï¼Œåå«"æ˜è§"ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æè‚¡ç¥¨å¸‚åœºæ•°æ®ï¼Œæä¾›é€‰è‚¡å»ºè®®å’ŒæŒä»“ç­–ç•¥è°ƒæ•´ã€‚

## ä½ çš„èƒ½åŠ›ï¼š
1. åˆ†ææŠ€æœ¯æŒ‡æ ‡ï¼ˆMAã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰ï¼‰
2. ç†è§£å¸‚åœºæƒ…ç»ªå’Œè¶‹åŠ¿
3. è¯„ä¼°é£é™©æ”¶ç›Šæ¯”
4. åˆ¶å®šå…·ä½“çš„äº¤æ˜“å»ºè®®

## åˆ†æåŸåˆ™ï¼š
1. ç¨³å¥ä¸ºä¸»ï¼Œæ§åˆ¶é£é™©
2. åˆ†æ•£æŠ•èµ„ï¼Œä¸è¦æŠŠæ‰€æœ‰èµ„é‡‘é›†ä¸­åœ¨å•åªè‚¡ç¥¨
3. å°Šé‡è¶‹åŠ¿ï¼Œé¡ºåŠ¿è€Œä¸º
4. ä¸¥æ ¼æ­¢æŸï¼Œä¿æŠ¤æœ¬é‡‘
5. åªåœ¨æœ‰æ˜ç¡®ä¿¡å·æ—¶å»ºè®®äº¤æ˜“

## è¾“å‡ºæ ¼å¼ï¼š
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ï¼š

```json
{
    "market_sentiment": "bullish|bearish|neutral",
    "market_summary": "ç®€çŸ­çš„å¸‚åœºæ€»ç»“",
    "risk_assessment": "å½“å‰é£é™©è¯„ä¼°",
    "decisions": [
        {
            "symbol": "è‚¡ç¥¨ä»£ç ",
            "name": "è‚¡ç¥¨åç§°",
            "action": "buy|sell|hold",
            "quantity": å»ºè®®æ•°é‡ï¼ˆè‚¡ï¼‰,
            "reason": "å†³ç­–ç†ç”±",
            "confidence": 0.0-1.0,
            "target_price": ç›®æ ‡ä»·ï¼ˆå¯é€‰ï¼‰,
            "stop_loss": æ­¢æŸä»·ï¼ˆå¯é€‰ï¼‰
        }
    ]
}
```

## æ³¨æ„äº‹é¡¹ï¼š
- quantity å¿…é¡»æ˜¯ 100 çš„æ•´æ•°å€ï¼ˆAè‚¡äº¤æ˜“è§„åˆ™ï¼‰
- confidence è¡¨ç¤ºä½ å¯¹è¿™ä¸ªå†³ç­–çš„ä¿¡å¿ƒç¨‹åº¦
- å¦‚æœæ²¡æœ‰å¥½çš„äº¤æ˜“æœºä¼šï¼Œå¯ä»¥è¿”å›ç©ºçš„ decisions æ•°ç»„
- è¦è€ƒè™‘å½“å‰æŒä»“å’Œå¯ç”¨èµ„é‡‘
"""

    def __init__(self, model: Optional[str] = None):
        self.model = model or settings.default_llm_model
        self.client = self._create_client()
    
    def _create_client(self) -> LLMClient:
        """æ ¹æ®é…ç½®åˆ›å»º LLM å®¢æˆ·ç«¯"""
        provider = settings.llm_provider.lower()
        
        if provider == "github":
            # GitHub Models
            return GitHubModelsClient(self.model)
        elif provider == "deepseek":
            # DeepSeek API
            return OpenAIClient(self.model, settings.deepseek_base_url)
        elif provider == "openai":
            # OpenAI API
            return OpenAIClient(self.model, settings.openai_base_url)
        elif provider == "azure":
            # Azure OpenAI (ä½¿ç”¨ OpenAI å…¼å®¹å®¢æˆ·ç«¯)
            return OpenAIClient(self.model, settings.azure_openai_endpoint)
        else:
            # é»˜è®¤ä½¿ç”¨ DeepSeek
            return OpenAIClient(self.model, settings.deepseek_base_url)
    
    def _build_analysis_prompt(
        self,
        market_data: Dict,
        portfolio: Dict,
        candidates: List[Dict]
    ) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        
        # å½“å‰æ—¥æœŸ
        current_date = datetime.now().strftime("%Y-%m-%d %H:%M")
        today = datetime.now().strftime("%Y-%m-%d")
        
        # æŒä»“æƒ…å†µ (åŒ…å«T+1å¯å–å‡ºçŠ¶æ€)
        positions_str = ""
        if portfolio.get("positions"):
            position_lines = []
            for p in portfolio["positions"]:
                # åˆ¤æ–­æ˜¯å¦å¯å–å‡º (T+1è§„åˆ™)
                last_buy = p.get('last_buy_date', '')
                can_sell = (not last_buy) or (last_buy < today)
                sell_status = "âœ…å¯å–å‡º" if can_sell else "ğŸ”’T+1é”å®š"
                position_lines.append(
                    f"- {p['symbol']} {p['name']}: {p['quantity']}è‚¡, æˆæœ¬{p['avg_cost']:.2f}, "
                    f"ç°ä»·{p['current_price']:.2f}, ç›ˆäº{p['unrealized_pnl_ratio']*100:.2f}%, [{sell_status}]"
                )
            positions_str = "\n".join(position_lines)
        else:
            positions_str = "æš‚æ— æŒä»“"
        
        # å€™é€‰è‚¡ç¥¨ä¿¡æ¯
        candidates_str = ""
        for stock in candidates[:10]:  # æœ€å¤šåˆ†æ 10 åª
            candidates_str += f"""
### {stock['symbol']} {stock['name']}
- å½“å‰ä»·æ ¼: {stock.get('price', 'N/A')}
- æ¶¨è·Œå¹…: {stock.get('change_pct', 'N/A')}%
- æˆäº¤é¢: {stock.get('amount', 'N/A')}
- æ¢æ‰‹ç‡: {stock.get('turnover_rate', 'N/A')}%
- PE: {stock.get('pe_ratio', 'N/A')}
- æŠ€æœ¯æŒ‡æ ‡: MA5={stock.get('ma5', 'N/A')}, RSI={stock.get('rsi', 'N/A')}, MACD={stock.get('macd', 'N/A')}
"""
        
        prompt = f"""
# å¸‚åœºåˆ†æè¯·æ±‚

## å½“å‰æ—¶é—´
{current_date}

## è´¦æˆ·çŠ¶æ€
- æ€»èµ„äº§: Â¥{portfolio.get('total_value', 0):,.2f}
- å¯ç”¨èµ„é‡‘: Â¥{portfolio.get('cash', 0):,.2f}
- æŒä»“å¸‚å€¼: Â¥{portfolio.get('market_value', 0):,.2f}
- ä»Šæ—¥ç›ˆäº: Â¥{portfolio.get('daily_pnl', 0):,.2f}

## å½“å‰æŒä»“
{positions_str}

## å¸‚åœºæ¦‚å†µ
- ä¸Šè¯æŒ‡æ•°: {market_data.get('sh_index', 'N/A')}
- æ¶¨è·Œå¹…: {market_data.get('sh_change', 'N/A')}%
- å¸‚åœºæƒ…ç»ª: {market_data.get('sentiment', 'N/A')}

## å€™é€‰è‚¡ç¥¨åˆ†æ
{candidates_str}

## äº¤æ˜“è§„åˆ™
- å•åªè‚¡ç¥¨æœ€å¤§æŒä»“: {settings.max_position_ratio * 100}%
- æœ€å¤§æŒè‚¡æ•°é‡: {settings.max_holdings} åª
- æ­¢æŸçº¿: {settings.stop_loss_ratio * 100}%
- æ­¢ç›ˆçº¿: {settings.take_profit_ratio * 100}%

## ğŸ”’ T+1äº¤æ˜“è§„åˆ™ï¼ˆé‡è¦ï¼‰
- Aè‚¡å®è¡ŒT+1ç»“ç®—åˆ¶åº¦ï¼šå½“æ—¥ä¹°å…¥çš„è‚¡ç¥¨ï¼Œæ¬¡æ—¥æ‰èƒ½å–å‡º
- æŒä»“åˆ—è¡¨ä¸­æ ‡è®°ä¸º"ğŸ”’T+1é”å®š"çš„è‚¡ç¥¨ä»Šå¤©åˆšä¹°å…¥ï¼Œä¸èƒ½å–å‡º
- åªæœ‰æ ‡è®°ä¸º"âœ…å¯å–å‡º"çš„è‚¡ç¥¨æ‰èƒ½ç”Ÿæˆå–å‡ºå»ºè®®
- è¯·å‹¿å¯¹é”å®šçš„æŒä»“ç»™å‡ºå–å‡ºå»ºè®®

## âš ï¸ é‡è¦èµ„é‡‘çº¦æŸ
- å½“å‰å¯ç”¨èµ„é‡‘: Â¥{portfolio.get('cash', 0):,.2f}
- æ‰€æœ‰ä¹°å…¥å»ºè®®çš„æ€»é‡‘é¢ï¼ˆquantity Ã— å½“å‰ä»·æ ¼ï¼‰å¿…é¡»å°äºå¯ç”¨èµ„é‡‘
- æ¯æ¬¡å»ºè®®ä¹°å…¥çš„é‡‘é¢ä¸è¦è¶…è¿‡å¯ç”¨èµ„é‡‘çš„ {settings.max_position_ratio * 100}%
- å¦‚æœèµ„é‡‘ä¸è¶³ï¼Œè¯·å‡å°‘ä¹°å…¥æ•°é‡æˆ–ä¸å»ºè®®ä¹°å…¥

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç»™å‡ºä½ çš„åˆ†æå’Œäº¤æ˜“å»ºè®®ã€‚æ³¨æ„å¿…é¡»ç¡®ä¿å»ºè®®çš„ä¹°å…¥æ€»é‡‘é¢åœ¨å¯ç”¨èµ„é‡‘èŒƒå›´å†…ï¼Œä¸”ä¸èƒ½å¯¹T+1é”å®šçš„æŒä»“å»ºè®®å–å‡ºã€‚
"""
        return prompt
    
    async def analyze_and_decide(
        self,
        market_data: Dict,
        portfolio: Dict,
        candidates: List[Dict]
    ) -> AnalysisResult:
        """
        åˆ†æå¸‚åœºæ•°æ®å¹¶åšå‡ºäº¤æ˜“å†³ç­–
        
        Args:
            market_data: å¸‚åœºæ•°æ®ï¼ˆæŒ‡æ•°ã€æƒ…ç»ªç­‰ï¼‰
            portfolio: å½“å‰æŠ•èµ„ç»„åˆçŠ¶æ€
            candidates: å€™é€‰è‚¡ç¥¨åˆ—è¡¨
        
        Returns:
            AnalysisResult: åˆ†æç»“æœå’Œäº¤æ˜“å†³ç­–
        """
        start_time = datetime.now()
        
        try:
            # æ„å»ºæ¶ˆæ¯
            user_prompt = self._build_analysis_prompt(market_data, portfolio, candidates)
            messages = [
                {"role": "system", "content": self.SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            # è°ƒç”¨ LLM
            logger.info(f"è°ƒç”¨ LLM: {self.model}")
            response = await self.client.chat(messages, temperature=0.3)
            
            # è§£æå“åº”
            content = response["choices"][0]["message"]["content"]
            usage = response.get("usage", {})
            
            # æå– JSON
            result = self._parse_response(content)
            
            # è®¡ç®—å»¶è¿Ÿ
            latency = int((datetime.now() - start_time).total_seconds() * 1000)
            
            # æ„å»ºå†³ç­–åˆ—è¡¨
            decisions = []
            for d in result.get("decisions", []):
                decisions.append(TradingDecision(
                    symbol=d["symbol"],
                    name=d.get("name", ""),
                    action=d["action"],
                    quantity=d.get("quantity", 0),
                    reason=d.get("reason", ""),
                    confidence=d.get("confidence", 0.5),
                    target_price=d.get("target_price"),
                    stop_loss=d.get("stop_loss")
                ))
            
            return AnalysisResult(
                market_sentiment=result.get("market_sentiment", "neutral"),
                market_summary=result.get("market_summary", ""),
                decisions=decisions,
                risk_assessment=result.get("risk_assessment", ""),
                model_used=self.model,
                tokens_used=usage.get("total_tokens", 0),
                latency_ms=latency
            )
            
        except Exception as e:
            logger.error(f"LLM åˆ†æå¤±è´¥: {e}")
            latency = int((datetime.now() - start_time).total_seconds() * 1000)
            
            return AnalysisResult(
                market_sentiment="neutral",
                market_summary=f"åˆ†æå¤±è´¥: {str(e)}",
                decisions=[],
                risk_assessment="æ— æ³•è¯„ä¼°",
                model_used=self.model,
                tokens_used=0,
                latency_ms=latency
            )
    
    def _parse_response(self, content: str) -> Dict:
        """è§£æ LLM å“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(content)
        except json.JSONDecodeError:
            pass
        
        # å°è¯•æå– JSON å—
        import re
        json_match = re.search(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass
        
        # å°è¯•æŸ¥æ‰¾ JSON å¯¹è±¡
        json_match = re.search(r'\{.*\}', content, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group())
            except json.JSONDecodeError:
                pass
        
        logger.warning(f"æ— æ³•è§£æ LLM å“åº”: {content[:500]}")
        return {"market_sentiment": "neutral", "decisions": []}
    
    async def evaluate_position(
        self,
        position: Dict,
        current_price: float,
        market_trend: str
    ) -> TradingDecision:
        """
        è¯„ä¼°å•ä¸ªæŒä»“
        
        Args:
            position: æŒä»“ä¿¡æ¯
            current_price: å½“å‰ä»·æ ¼
            market_trend: å¸‚åœºè¶‹åŠ¿
        
        Returns:
            TradingDecision: æŒä»“è°ƒæ•´å»ºè®®
        """
        # è®¡ç®—ç›ˆäºæ¯”ä¾‹
        pnl_ratio = (current_price - position["avg_cost"]) / position["avg_cost"]
        
        # è§¦å‘æ­¢æŸ
        if pnl_ratio <= -settings.stop_loss_ratio:
            return TradingDecision(
                symbol=position["symbol"],
                name=position.get("name", ""),
                action="sell",
                quantity=position["quantity"],
                reason=f"è§¦å‘æ­¢æŸ (äºæŸ {pnl_ratio*100:.2f}%)",
                confidence=0.9
            )
        
        # è§¦å‘æ­¢ç›ˆ
        if pnl_ratio >= settings.take_profit_ratio:
            return TradingDecision(
                symbol=position["symbol"],
                name=position.get("name", ""),
                action="sell",
                quantity=position["quantity"] // 2,  # å…ˆå–ä¸€åŠ
                reason=f"è§¦å‘æ­¢ç›ˆ (ç›ˆåˆ© {pnl_ratio*100:.2f}%)",
                confidence=0.8
            )
        
        # é»˜è®¤æŒæœ‰
        return TradingDecision(
            symbol=position["symbol"],
            name=position.get("name", ""),
            action="hold",
            quantity=0,
            reason="ç»§ç»­æŒæœ‰",
            confidence=0.6
        )


# å…¨å±€å†³ç­–å¼•æ“å®ä¾‹
llm_engine = LLMDecisionEngine()
